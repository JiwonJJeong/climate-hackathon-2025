import os
import pickle
import pandas as pd
import numpy as np

# Global variable to store the loaded model
model_data = None

def load_model():
    """Load the pickled model once at startup"""
    global model_data
    try:
        # Get the absolute path to the model file
        current_dir = os.path.dirname(os.path.abspath(__file__))
        model_path = os.path.join(current_dir, '..', 'data-exploration', 'climate_health_model.pkl')
        model_path = os.path.abspath(model_path)
        
        print(f"ðŸ” Looking for model at: {model_path}")
        print(f"ðŸ“ Model file exists: {os.path.exists(model_path)}")
        
        with open(model_path, 'rb') as f:
            model_data = pickle.load(f)
        print("âœ… Climate health model loaded successfully!")
        print(f"ðŸ“Š Model type: {type(model_data)}")
        return True
    except Exception as e:
        print(f"âŒ Error loading model: {e}")
        model_data = None
        return False

def predict_risk_percentage(age, aqi, diabetes, hypertension, heart_disease):
    """
    Predict risk percentage using the trained climate health model
    
    Returns:
    - risk_percentage: predicted risk as percentage (0-100%)
    """
    if model_data is None:
        raise Exception("Model not loaded")
    
    # Create DataFrame with proper feature names to avoid sklearn warnings
    feature_names = ['AGE', 'AQI', 'Diabetes', 'Hypertension', 'Heart_Disease']
    input_df = pd.DataFrame([[age, aqi, diabetes, hypertension, heart_disease]], 
                           columns=feature_names)
    
    # Scale the input
    input_scaled = model_data['scaler'].transform(input_df)
    
    # Predict probability and convert to percentage
    risk_probability = model_data['model'].predict_proba(input_scaled)[0, 1]
    risk_percentage = risk_probability * 100
    
    return round(risk_percentage, 2)

def predict_risk_batch(data_df):
    """
    Predict risk percentage for multiple patients at once (MUCH FASTER)
    
    Parameters:
    - data_df: DataFrame with columns ['Age', 'AQI', 'diabetes', 'hypertension', 'heart_disease']
    
    Returns:
    - list of risk percentages
    """
    if model_data is None:
        raise Exception("Model not loaded")
    
    # Prepare feature names
    feature_names = ['AGE', 'AQI', 'Diabetes', 'Hypertension', 'Heart_Disease']
    
    # Create input DataFrame with proper feature names
    input_df = pd.DataFrame({
        'AGE': data_df['Age'].astype(int),
        'AQI': data_df['AQI'].astype(int), 
        'Diabetes': data_df['diabetes'].astype(int),
        'Hypertension': data_df['hypertension'].astype(int),
        'Heart_Disease': data_df['heart_disease'].astype(int)
    })
    
    # Handle any NaN values
    input_df = input_df.fillna(0)
    
    # Scale all data at once (VECTORIZED - much faster)
    input_scaled = model_data['scaler'].transform(input_df)
    
    # Predict all probabilities at once (BATCH PREDICTION - much faster)
    risk_probabilities = model_data['model'].predict_proba(input_scaled)[:, 1]
    risk_percentages = (risk_probabilities * 100).round(2)
    
    return risk_percentages.tolist()

def get_weather(date: str, weather_path: str | None = None) -> pd.DataFrame:
    """
    Load weather data and return filtered rows for a given YYYYMMDD date.

    Parameters:
    - date: string like '20170101'
    - weather_path: optional explicit path to weather_data.csv

    Returns:
    - pandas DataFrame with columns ['zipcode', 'AQI'] for the given date
    """
    # Resolve default path relative to this file
    if weather_path is None:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        weather_path = os.path.abspath(os.path.join(current_dir, 'data', 'weather_data.csv'))

    if not os.path.exists(weather_path):
        raise FileNotFoundError(f"Weather data not found at {weather_path}")

    # Read only necessary columns for speed
    df = pd.read_csv(weather_path, usecols=['date', 'zipcode', 'AQI'])
    filtered = df[df['date'].astype(str) == str(date)][['zipcode', 'AQI']]
    return filtered.reset_index(drop=True)